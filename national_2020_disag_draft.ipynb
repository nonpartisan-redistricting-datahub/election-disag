{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787a8be7-71f9-444a-a145-6a2931a39a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import geopandas as gp\n",
    "import pandas as pd\n",
    "import maup\n",
    "import numpy as np\n",
    "maup.progress.enabled = False\n",
    "import warnings\n",
    "import time \n",
    "import zipfile\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65497b1-7240-47a0-89e8-408f6ca7e40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "wd = os.getcwd()\n",
    "block_fold = os.path.join(wd,'extracted_blocks')\n",
    "prec_fold = os.path.join(wd,'precs_2020')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a845d987-2c5b-4a26-9d75-ae9cb122d012",
   "metadata": {},
   "outputs": [],
   "source": [
    "block_dict = {}\n",
    "for folder in os.listdir(block_fold):\n",
    "    fp = os.path.join(block_fold,folder)\n",
    "    for file in os.listdir(fp):\n",
    "        if file.endswith('.shp'):\n",
    "            sa = file.split('_')[0]\n",
    "            #print('on: ', sa)\n",
    "            gdf = gp.read_file(os.path.join(fp,file))\n",
    "            #print(sa, ' read!')\n",
    "            block_dict.update({sa:gdf})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c8476f-c424-46bc-b83f-7c682e88cd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prec_dict = {}\n",
    "for folder in os.listdir(prec_fold):\n",
    "    fp = os.path.join(prec_fold,folder)\n",
    "    for file in os.listdir(fp):\n",
    "        if file.endswith('.shp'):\n",
    "            sa = file.split('_')[0]\n",
    "            #print('on: ',sa)\n",
    "            gdf = gp.read_file(os.path.join(fp,file))\n",
    "            #print(sa, ' read!')\n",
    "            prec_dict.update({sa:gdf})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5902dbf6-e7eb-4848-a57b-bc248d50d180",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_block_match(prec_sa,block_dict=block_dict):\n",
    "    block_gdf = block_dict.get(prec_sa)\n",
    "    return block_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a88f69b-cf98-443f-95e3-c13eefb437e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_valid_rows(block_gdf, precinct_gdf):\n",
    "    prec_geom = precinct_gdf.geometry\n",
    "    valid_rows = precinct_gdf[~(prec_geom.isna() | prec_geom.is_empty)]\n",
    "    valid_rows = valid_rows[valid_rows.is_valid]\n",
    "    if len(valid_rows)!=len(precinct_gdf):\n",
    "        #print('There are rows that are NOT valid in the precinct file!')\n",
    "        not_valid_rows = precinct_gdf[(prec_geom.isna() | prec_geom.is_empty)]\n",
    "        not_valid_rows = not_valid_rows[~not_valid_rows.is_valid]\n",
    "        #display(not_valid_rows)\n",
    "        \n",
    "    block_geom = block_gdf.geometry\n",
    "    block_valid_rows = block_gdf[~(block_geom.isna() | block_geom.is_empty)]\n",
    "    block_valid_rows = block_valid_rows[block_valid_rows.is_valid]\n",
    "    if len(block_valid_rows)!=len(block_gdf):\n",
    "        #print('There are rows that are NOT valid in the block file!')\n",
    "        not_valid_block = block_gdf[(block_geom.isna() | block_geom.is_empty)]\n",
    "        not_valid_block = not_valid_block[~not_valid_block.is_valid]\n",
    "        #display(not_valid_block)\n",
    "\n",
    "    #print('Valid rows check complete!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7780b4-f837-4c09-9016-66f30eb5e076",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_buffer(gdf):\n",
    "    \"\"\"\n",
    "    return (GeoDataFrame) with the 'bufer(0) trick' applied\n",
    "    :gdf: (GeoDataFrame) object\n",
    "    Can be useful when trying to mitigate 'self-intersection' issues\n",
    "    \"\"\"\n",
    "    #buffered = gdf.buffer(0)\n",
    "    #gdf.drop(columns=[\"geometry\"])\n",
    "    # gdf['geometry'] = gdf.apply(lambda x: x.geometry.buffer(0), axis=1)\n",
    "    #gdf[\"geometry\"] = buffered\n",
    "    \n",
    "    gdf['geometry'] = gdf['geometry'].buffer(0)\n",
    "    return gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd5268a-8d8e-4adc-b0e8-6bc4560c13b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def column_total_check(election_columns, block_gdf, precinct_gdf):\n",
    "    for val in election_columns:\n",
    "        #print(block_gdf.value_counts)\n",
    "        vote_dif = block_gdf[val].sum()-precinct_gdf[val].sum()\n",
    "        if (abs(vote_dif) <=1e-1):\n",
    "            print(val+\": EQUAL\", ' - total: ', 'block:', str(block_gdf[val].sum()), 'prec:', str(precinct_gdf[val].sum()), 'diff:', block_gdf[val].sum()-precinct_gdf[val].sum())\n",
    "        else:\n",
    "            print(val+\": DIFFERENCE OF \" + str(vote_dif)+ \" VOTES\", ' - block total: ', str(block_gdf[val].sum()), ', precinct total: ', str(precinct_gdf[val].sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e514d791-30b7-478d-870b-98609a2eca2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_col(precincts,election_cols):\n",
    "    elec_copy = election_cols\n",
    "    unique_id = False\n",
    "    election_cols.append('geometry')\n",
    "    for i in list(precincts.columns):\n",
    "        if len(precincts[i].unique())==len(precincts):\n",
    "            if i not in elec_copy:\n",
    "                unique_id = i\n",
    "                #print('Unique ID is: ' ,unique_id)\n",
    "                break\n",
    "    if unique_id == False:\n",
    "        dict_of_lens ={}\n",
    "        for i in precincts.columns:\n",
    "            if i not in elec_copy:\n",
    "                dict_of_lens.update({i:len(precincts[i].unique())})\n",
    "        max1_len=0\n",
    "        max2_len=0\n",
    "        max1=False\n",
    "        max2=False\n",
    "        for k,v in dict_of_lens.items():\n",
    "            if v>max1_len:\n",
    "                max2_len = max1_len\n",
    "                max2 = max1\n",
    "                max1_len = v\n",
    "                max1 = k\n",
    "\n",
    "            elif v>max2_len:\n",
    "                max2_len = v\n",
    "                max2 = k\n",
    "            else:\n",
    "                continue\n",
    "        unique_id = str(max1)+'_'+str(max2)\n",
    "        #print('Unique ID is: ', unique_id)\n",
    "        precincts[unique_id] = precincts.apply(lambda x: str(x[max1])+ ' - '+str(x[max2]),axis=1)\n",
    "    if len(precincts[unique_id].unique())!=len(precincts):\n",
    "        precincts['counter'] = range(len(precincts))\n",
    "        precincts[unique_id] = precincts.apply(lambda x: str(x[unique_id]) + ' - ' + str(x['counter']),axis=1)\n",
    "    return unique_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328854cf-6b79-4478-b056-882d4472e16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_election_cols(precincts):\n",
    "    election_columns = []\n",
    "    for i in list(precincts.columns):\n",
    "        if i.startswith('G20'):\n",
    "            election_columns.append(i)\n",
    "    #print('Election columns: ', election_columns)\n",
    "    return election_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf94b29-f3cf-4a05-b7e2-ef1ca6f734cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_and_remove_null_blocks(blocks,precincts,unique_id):\n",
    "    if len(blocks[blocks['assignment'].isna()])!=0:\n",
    "        #print('There are blocks with NO assignment!')\n",
    "        na_blocks = blocks[blocks['assignment'].isna()]\n",
    "        na_blocks_not_zero = na_blocks[na_blocks['VAP_MOD']>0]\n",
    "        display(na_blocks_not_zero)\n",
    "        #print(list(na_blocks_not_zero['GEOID20']))\n",
    "        blocks = blocks[~blocks['assignment'].isna()]\n",
    "    blocks['PRECINCT_ID'] = blocks['assignment'].map(lambda x: str(precincts.loc[x][unique_id]))\n",
    "    return blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce5e8ae-fffb-4a65-8ba9-68392e0f433b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_missing_precs(precincts,blocks,unique_id):\n",
    "    not_in_blocks = list(set(precincts[unique_id]) - set(blocks['PRECINCT_ID']))\n",
    "    if not_in_blocks!=list(set()):\n",
    "        #print('Precincts that did NOT make it to any blocks: ', not_in_blocks)\n",
    "        print(\"\")\n",
    "    return not_in_blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc290ef8-035b-48c2-979a-486bf34e9d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def agg_vap_to_precs(blocks,precincts,assignment):\n",
    "    precincts['VAP_MOD'] = blocks['VAP_MOD'].groupby(assignment).sum()\n",
    "    return precincts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d87498-cc9d-4a68-ba63-5944a89c017f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_precs_with_no_vap(precincts):\n",
    "    precincts_with_no_pop = precincts.index[precincts['VAP_MOD'].isin([0,0.0])].tolist()\n",
    "    #print('Precincts with no popultion: ', precincts_with_no_pop)\n",
    "    return precincts_with_no_pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d972214-8d0b-4d84-a57e-5587726a4119",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_block_vap_1(precincts_with_no_pop,blocks,precincts):\n",
    "    blocks_to_mod = blocks[blocks['assignment'].isin(precincts_with_no_pop)]['GEOID20'].to_list()\n",
    "    blocks['VAP_MOD'] = blocks.apply(lambda x: 1 if x['GEOID20'] in blocks_to_mod else x['VAP_MOD'],axis=1)\n",
    "    #print('Block modification complete!')\n",
    "    return blocks, blocks_to_mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1745adde-35c2-4f29-97d3-6ae8382bf8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_files(precincts,blocks):\n",
    "    check_valid_rows(blocks,precincts)\n",
    "    fix_buffer(precincts)\n",
    "    fix_buffer(blocks)\n",
    "    precincts = precincts.to_crs(blocks.crs) \n",
    "    return precincts,blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc3ad5f-a749-4528-82e2-b159d668819e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def allocate_votes(precincts,blocks,unique_id,election_columns,assignment):\n",
    "    not_in_blocks = check_missing_precs(precincts,blocks,unique_id)\n",
    "    precincts = agg_vap_to_precs(blocks, precincts,assignment)\n",
    "    precincts_with_no_pop = get_precs_with_no_vap(precincts)\n",
    "    vap_output = make_block_vap_1(precincts_with_no_pop,blocks,precincts)\n",
    "    blocks = vap_output[0]\n",
    "    blocks_to_mod = vap_output[1]\n",
    "    precincts = agg_vap_to_precs(blocks,precincts,assignment)\n",
    "    weights = blocks.VAP_MOD/assignment.map(precincts.VAP_MOD)\n",
    "    print('Weights complete!')\n",
    "    if 'geometry' in election_columns:\n",
    "        election_columns.remove('geometry')\n",
    "    blocks[election_columns] = maup.prorate(assignment, precincts[election_columns], weights)\n",
    "    print('Proration complete!')\n",
    "    return precincts,blocks,blocks_to_mod,precincts_with_no_pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e56d3e-aace-48a7-85a7-70898d97de4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def maup_assign(blocks,precincts):\n",
    "    try:\n",
    "        assignment = maup.assign(blocks, precincts)\n",
    "        blocks['assignment'] = assignment\n",
    "        print('MAUP complete!')\n",
    "        return blocks, assignment\n",
    "    except ValueError as v:\n",
    "        print(blocks.is_valid)\n",
    "        print(precincts.is_valid)\n",
    "        print(v)\n",
    "        print('Could not run MAUP!')\n",
    "    except IndexError as i:\n",
    "        print(blocks.is_valid)\n",
    "        print(precincts.is_valid)\n",
    "        print(v)\n",
    "        print('Could not run MAUP!')\n",
    "    except TypeError as t:\n",
    "        print(blocks.is_valid)\n",
    "        print(precincts.is_valid)\n",
    "        print(t)\n",
    "        print('Could not run MAUP!')\n",
    "    except:\n",
    "        try:\n",
    "            precincts['geometry'] = precincts['geometry'].buffer(0)\n",
    "            blocks['geometry'] = blocks['geometry'].buffer(0)\n",
    "            assignment = maup.assign(blocks, precincts)\n",
    "            blocks['assignment'] = assignment\n",
    "            print('MAUP complete!')\n",
    "            return blocks,assignment\n",
    "        except:\n",
    "            print('Still could not run MAUP!')\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f98221b-c2ab-4cca-9124-8353980ed045",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_sums_by_precinct(precincts,blocks,unique_id,election_columns):\n",
    "    election_col = election_columns.copy()\n",
    "    election_col.append('VAP_MOD')\n",
    "    #print('STARTING ADDITIONAL SUM BY PRECINCT CHECK')\n",
    "    blocks_grouped = blocks.groupby('PRECINCT_ID').sum()\n",
    "    blocks_grouped.reset_index(inplace=True,drop=False)\n",
    "    for i in blocks_grouped['PRECINCT_ID']:\n",
    "        sub = blocks_grouped[blocks_grouped['PRECINCT_ID']==i]\n",
    "        precinct_sub = precincts[precincts[unique_id]==i]\n",
    "        for col in election_col:\n",
    "            if round(sub[col].sum()) != round(precinct_sub[col].sum()):\n",
    "                continue\n",
    "                print(\"Blocks sum to: \", sub[col].sum(), ' for ', col, ' in precinct: ', i)\n",
    "                print(\"Precincts sum to: \",precinct_sub[col].sum(), ' for ', col, ' in precinct: ', i)\n",
    "                print('')   \n",
    "    #print('SUM BY PRECINCT CHECK COMPLETE!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e824d858-4187-422a-b582-6ad9a3bcd37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def allocate_missing_precincts(precincts,blocks,unique_id,blocks_to_mod,election_columns,precincts_with_no_pop):\n",
    "    not_in_blocks = check_missing_precs(precincts,blocks,unique_id)\n",
    "    if len(not_in_blocks) !=0:\n",
    "        #print('Missing precincts: ', not_in_blocks)\n",
    "        missing_precs = precincts[precincts[unique_id].isin(not_in_blocks)]\n",
    "        missing_precs['total_votes'] = missing_precs[election_columns].sum(axis=1)\n",
    "        missing_precs = missing_precs[~missing_precs['total_votes'].isin([0,0.0])]\n",
    "        if len(missing_precs)!=0:\n",
    "            b_clipped = gp.clip(blocks,missing_precs)\n",
    "            b_clipped = b_clipped[b_clipped.geom_type.isin(['Polygon','MultiPolygon'])]\n",
    "            allocation_dict = {}\n",
    "            for i in missing_precs[unique_id]:\n",
    "                sub_prec = missing_precs[missing_precs[unique_id]==i]\n",
    "                b_sub = gp.clip(b_clipped,sub_prec)\n",
    "                b_sub['area'] = b_sub.area\n",
    "                b_sub= b_sub.nlargest(1,'area')\n",
    "                geoid = str(list(b_sub['GEOID20'])[0])\n",
    "                allocation_dict.update({i: geoid})\n",
    "            #print('ALLOCATION DICTIONARY: ', allocation_dict)\n",
    "\n",
    "            for i in missing_precs[unique_id]:\n",
    "                #print('Starting: ', i)\n",
    "                sub_prec = missing_precs[missing_precs[unique_id] == i]\n",
    "                #display(sub_prec)\n",
    "                block_match = allocation_dict.get(i)\n",
    "                #print('Block match: ', block_match)\n",
    "                blocks.loc[blocks['GEOID20'] == block_match, 'PRECINCT_ID'] = ' & '.join([str(list(blocks[blocks['GEOID20'] == block_match]['PRECINCT_ID'])[0]), i])\n",
    "                #display(blocks[blocks['GEOID20']==block_match])\n",
    "                for col in election_columns:\n",
    "                    blocks_col_cur_sum = blocks[blocks['GEOID20'] == block_match][col].sum()\n",
    "                    #print('Current sum for ', col, ': ', blocks_col_cur_sum)\n",
    "                    blocks.loc[blocks['GEOID20'] == block_match, col] = sub_prec[col].sum() + blocks_col_cur_sum\n",
    "                    #print('New sum for ', col, ': ',  sub_prec[col].sum() + blocks_col_cur_sum)\n",
    "    blocks['VAP_MOD'] = blocks.apply(lambda x: 0 if x['GEOID20'] in blocks_to_mod else x['VAP_MOD'],axis=1)\n",
    "    try:\n",
    "        precincts['VAP_MOD'] = precincts.apply(lambda x: 0 if x.index in precincts_with_no_pop else x['VAP_MOD'],axis=1)\n",
    "    except:\n",
    "        precincts['index'] = precincts.index\n",
    "        precincts['VAP_MOD'] = precincts.apply(lambda x: 0 if x['index'] in precincts_with_no_pop else x['VAP_MOD'],axis=1)\n",
    "        precincts.drop(columns = 'index',inplace=True)\n",
    "    check_sums_by_precinct(precincts,blocks,unique_id,election_columns)\n",
    "    print('Missing precincts allocation complete!')\n",
    "    return blocks,precincts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ad8c7c-2fcf-4407-82ae-67977efcf7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_and_sort(blocks,original_blocks):\n",
    "    if len(blocks)!=len(original_blocks):\n",
    "        missing_blocks = original_blocks[~original_blocks['GEOID20'].isin(list(blocks['GEOID20']))].copy(deep=True)\n",
    "        blocks = gp.GeoDataFrame(pd.concat([blocks,missing_blocks]),crs=blocks.crs)\n",
    "        blocks.fillna({'PRECINCT_ID': 'N/A'}, inplace=True)\n",
    "    blocks.fillna(0,inplace=True)\n",
    "    blocks.drop(columns='assignment',inplace=True)\n",
    "    blocks_list = list(blocks.columns)\n",
    "    blocks_list.remove('GEOID20')\n",
    "    blocks_list.remove('PRECINCT_ID')\n",
    "    blocks_list.remove('VAP_MOD')\n",
    "    blocks_list.remove('geometry')\n",
    "    blocks['STATEFP'] = blocks['GEOID20'].apply(lambda x: str(x[:2]))\n",
    "    blocks['COUNTYFP'] = blocks['GEOID20'].apply(lambda x: str(x[2:5]))\n",
    "    blocks.rename(columns = {'PRECINCT_ID':'PRECINCTID'},inplace=True)\n",
    "    col_order = ['GEOID20','STATEFP','COUNTYFP','PRECINCTID','VAP_MOD'] + blocks_list + ['geometry']\n",
    "    blocks = blocks[col_order]\n",
    "    blocks.sort_values(by='GEOID20',inplace=True)\n",
    "    return blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844b86e0-2186-4e65-8dc9-9e73986cf3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_vap(blocks,orig_blocks):\n",
    "    column_total_check(['VAP_MOD'],blocks,orig_blocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d728eb-2ba1-4458-a9d2-aa8cc0344f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_totals_original (block,prec):\n",
    "    display(block.head())\n",
    "    display(prec.head())\n",
    "    cols_to_check = get_election_cols(prec)\n",
    "    column_total_check(cols_to_check,block,prec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd78f46b-3b7f-44b5-b722-5bd92b052f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_assignment(blocks,precincts,assignment,sa):\n",
    "    if sa == 'wa':\n",
    "        bindex = blocks.index[blocks['GEOID20'] == '530299701002015'].tolist()[0]\n",
    "        print(assignment.iloc[bindex])\n",
    "        print('Block index to modify in Washington: ', bindex)\n",
    "        pindex = float(precincts.index[precincts['PRECNAME'] == 'N WHIDBEY 01'].tolist()[0])\n",
    "        print('Precinct index to modify in Washington: ', pindex)\n",
    "        assignment.update(pd.Series([pindex], index=[bindex]))\n",
    "        print('Assignment updated!')\n",
    "        print(assignment.iloc[bindex])\n",
    "        blocks['assignment'] = assignment\n",
    "        return blocks,assignment\n",
    "    elif sa == 'or':\n",
    "        bindex = blocks.index[blocks['GEOID20'] == '410579601021095'].tolist()[0]\n",
    "        print('Block index to modify in Oregon: ', bindex)\n",
    "        pindex = float(precincts.index[precincts['NAME'] == 'FOLEY'].tolist()[0])\n",
    "        print(assignment.iloc[bindex])\n",
    "        print('Precinct index to modify in Oregon: ', pindex)\n",
    "        assignment.update(pd.Series([pindex], index=[bindex]))\n",
    "        print('Assignment updated!')\n",
    "        print(assignment.iloc[bindex])\n",
    "        blocks['assignment'] = assignment\n",
    "        return blocks,assignment\n",
    "    else:\n",
    "        return blocks,assignment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4cab73-28ae-4e78-9f4c-b06576457423",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zip_files(src, dst):\n",
    "    zf = zipfile.ZipFile(\"%s.zip\" % (dst), \"w\", zipfile.ZIP_DEFLATED)\n",
    "    abs_src = os.path.abspath(src)\n",
    "    for dirname, subdirs, files in os.walk(src):\n",
    "        for filename in files:\n",
    "            absname = os.path.abspath(os.path.join(dirname, filename))\n",
    "            arcname = absname[len(abs_src) + 1:]\n",
    "            #print ('zipping %s as %s' % (os.path.join(dirname, filename),arcname))\n",
    "            zf.write(absname, arcname)\n",
    "    zf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f41ec2-228c-47c5-be9c-b289904ce3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zip_directory(wd):\n",
    "    for i in os.listdir(wd):\n",
    "        src = os.path.join(wd,i)\n",
    "        dest_fold = os.path.join(os.getcwd(),'zipped')\n",
    "        if not os.path.exists(dest_fold):\n",
    "            os.mkdir(dest_fold)\n",
    "        dest = os.path.join(dest_fold,i)\n",
    "        zip_files(src,dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3efd9194-bcea-4b7f-80b8-bb452b3091db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_data(maup_dict):\n",
    "    extract_folder = os.path.join(wd,'extracted_disag')\n",
    "    if not os.path.exists(extract_folder):\n",
    "        os.mkdir(extract_folder)\n",
    "    for k,v in maup_dict.items():\n",
    "        start = time.time()\n",
    "        print('starting: ', k)\n",
    "        name = k+'_2020_gen_2020_blocks'\n",
    "        folder_name = os.path.join(extract_folder,name)\n",
    "        if not os.path.exists(folder_name):\n",
    "            os.mkdir(folder_name)\n",
    "        path = os.path.join(folder_name,name+'.shp')\n",
    "        for col in v.columns:\n",
    "            if col.startswith('G20'):\n",
    "                v[col] = v[col].apply(lambda x: round(x,2))\n",
    "        display(v.head(1))\n",
    "        v.to_file(path)\n",
    "        stop = time.time()\n",
    "        calc_time = round((stop-start)/60,2)\n",
    "        print(k,' is extracted in ', str(calc_time), ' minutes!')\n",
    "        zip_directory(extract_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0603c9cf-2de1-435b-b5f9-3fedfb61d09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_maup(precinct_name,precincts):\n",
    "    print('starting: ',precinct_name)\n",
    "    blocks = get_block_match(precinct_name)\n",
    "    original_blocks = blocks.copy(deep=True)\n",
    "    cleaned_outputs = clean_files(precincts,blocks)\n",
    "    precincts = cleaned_outputs[0]\n",
    "    blocks = cleaned_outputs[1]\n",
    "    election_columns = get_election_cols(precincts)\n",
    "    unique_id = get_unique_col(precincts,election_columns)\n",
    "    assign_out = maup_assign(blocks,precincts)\n",
    "    blocks = assign_out[0]\n",
    "    assignment = assign_out[1]\n",
    "    \n",
    "    reassign = append_assignment(blocks,precincts,assignment,precinct_name)\n",
    "    blocks = reassign[0]\n",
    "    assignment = reassign[1]\n",
    "    \n",
    "    blocks = check_and_remove_null_blocks(blocks,precincts,unique_id)\n",
    "    allocated_outputs = allocate_votes(precincts,blocks,unique_id,election_columns,assignment)\n",
    "    precincts = allocated_outputs[0]\n",
    "    blocks = allocated_outputs[1]\n",
    "    blocks_to_mod = allocated_outputs[2]\n",
    "    precincts_with_no_votes = allocated_outputs[3]\n",
    "    check_sums_by_precinct(precincts,blocks,unique_id,election_columns)\n",
    "    reallocated = allocate_missing_precincts(precincts,blocks,unique_id,blocks_to_mod,election_columns,precincts_with_no_votes)\n",
    "    blocks = reallocated[0]\n",
    "    precicts = reallocated[1]\n",
    "    blocks = fill_and_sort(blocks,original_blocks)\n",
    "    column_total_check(election_columns,blocks,precincts)\n",
    "    check_vap(blocks,original_blocks)\n",
    "    print('DISAG IS COMPLETE FOR: ', precinct_name.upper())\n",
    "    return blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca912253-6965-4e70-8bda-8f83d0aad932",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_maup(prec_dict=prec_dict):\n",
    "    maup_gdfs = {}\n",
    "    for k,v in prec_dict.items():\n",
    "        blocks = run_maup(k,v)\n",
    "        maup_gdfs.update({k:blocks})\n",
    "        #display(v.head(1))\n",
    "        check_totals_original(blocks,v)\n",
    "        print('*****************************************************************')\n",
    "    return maup_gdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c735b5-cfa8-4c09-b564-07d9dc729585",
   "metadata": {},
   "outputs": [],
   "source": [
    "maup_dict = iterate_maup(prec_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9772544f-e158-468c-b5d9-64046f026bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_data(maup_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
